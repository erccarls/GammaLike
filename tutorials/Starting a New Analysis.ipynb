{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting a New GammaLike Analysis\n",
    "\n",
    "The first step in a GammaLike analysis is to choose the spatial binning, energy binning, event selections etc.  GammaLike is especially computationally efficient because it first spends time generating the needed output files from the Fermi Science Tools.  After that, the instrument response functions are known and we can easily perform our template analyses on any models.  We will start by reproducing the analysis settings from [Calore et al (2015)](http://arxiv.org/abs/1409.0042), but with updates to Pass 8 data and the 3FGL point source catalog.  The comments below follow the Fermi Science Tools standard parameter nomencalture.  Comments inline describe the parameters, but additional information specific to Fermi can be found at http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/.  \n",
    "\n",
    "In addition to the analysis settings, we need to point GammaLike to the filepaths of the fermi event files and spacecraft files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/GammaLike/')\n",
    "\n",
    "\n",
    "# First we must import the Analyis \n",
    "from GammaLike import Analysis\n",
    "\n",
    "#-------------------------------\n",
    "# General Analysis Settings\n",
    "\n",
    "# basepath: This defines the base directory for storing all the generated analysis files. \n",
    "# It should have at least 10-20 GB free. \n",
    "basepath = '/data/GammaLike/testing'\n",
    "\n",
    "# tag: All the generated files carry this tag. Should be descriptive of analysis.\n",
    "tag = 'P8R2_CLEAN_V6_calore' \n",
    "\n",
    "#--------------------------------\n",
    "# Energy Binning Settings\n",
    "# The energy binning by default matches that of Calore et al 2014 (see 1409.0042 Eq.2 and discussion)\n",
    "# This consists of a few linear spaced bins at low energies followed by a rescursive binning definition.\n",
    "# If custom binning is required, just set the bin edges using prefix_bins=... and change n_bins=0\n",
    "prefix_bins=[300, 350, 400, 450, 500] # Fixed bins go here and are prepended to any additional recursive bins\n",
    "# These 4 settings are for recursive bin definitions.  To disable set n_bins=0\n",
    "n_bins = 20 # number of recursive bins\n",
    "E_min = 5e2 # Starting recusrion energy\n",
    "E_max = 5e5 # Max recursion energy\n",
    "gamma = 1.45 # Recursion index. \n",
    "\n",
    "#--------------------------------\n",
    "# Spatial Binning\n",
    "healpix_order = 8 # Healpix order.  8 gives ~0.24 degree pixel edge width.  Increase of 1 halves the bin size.\n",
    "\n",
    "#--------------------------------\n",
    "# Fermitools settings\n",
    "\n",
    "# phfile input to gtselect. Can be merged photon file or a text file containing paths of each weekly file\n",
    "#phfile_raw = '/data/fermi_data_1-8-14/phfile.txt' \n",
    "phfile_raw = '/data/fermi_data_6-26-15/phfile.txt' \n",
    "\n",
    "\n",
    "# scfile [filename]\n",
    "#           Spacecraft data file containing information such as the spacecraft\n",
    "#           pointing as a function of time. This file could be generated by\n",
    "#           gtorbsim for simulated observations (see the gtorbsim help for further\n",
    "#           explanation) or it can be obtained from the FERMI\n",
    "#           Science Support Center (FSSC) website for real observations.\n",
    "scfile = '/data/fermi_data_6-26-15/lat_spacecraft_merged.fits' # Path to spacecraft file\n",
    "\n",
    "\n",
    "# (evclass) [integer] \n",
    "#          Event class selection for pass 8 reprocessed data.\n",
    "#       -----------------------------------------\n",
    "#       |Class (Pass 8)|  evclass\n",
    "#       |----------------------------------------\n",
    "#       |Source        |  128  |\n",
    "#       |Clean         |  256  |\n",
    "#       |UltraCleanVeto|  1024 |\n",
    "#       -----------------------------------------\n",
    "# more info at http://fermi.gsfc.nasa.gov/ssc/data/analysis/documentation/Cicerone/Cicerone_LAT_IRFs/IRF_overview.html\n",
    "\n",
    "\n",
    "evclass = 128 # FermiTools evclass\n",
    "evtype = 3  \n",
    "\n",
    "\n",
    "# filter [string]\n",
    "#           This is the filter expression. The cuts are make using C-style\n",
    "#           relational syntax like for example: ! (not), && (and), || (or), !=\n",
    "#           (different), >, <, >=, <=, abs(), cos(), sin(), etc. Default is \n",
    "#           \"DATA_QUAL>0 && LAT_CONFIG==1 && ABS(ROCK_ANGLE)<52\".\n",
    "\n",
    "gtfilter = 'DATA_QUAL>0 && LAT_CONFIG==1 && ABS(ROCK_ANGLE)<52' # gtmktime cut\n",
    "\n",
    "# The fermi instrument response function.  Can get full list via command 'gtirfs'\n",
    "# ******MAKE SURE THIS MATCHES evclass and evtype above!************\n",
    "# Some common ones....\n",
    "# P8R2_CLEAN_V6\n",
    "# P8R2_CLEAN_V6::BACK\n",
    "# P8R2_CLEAN_V6::EDISP0\n",
    "# P8R2_CLEAN_V6::EDISP1\n",
    "# P8R2_CLEAN_V6::EDISP2\n",
    "# P8R2_CLEAN_V6::EDISP3\n",
    "# P8R2_CLEAN_V6::FRONT\n",
    "# P8R2_CLEAN_V6::PSF0\n",
    "# P8R2_CLEAN_V6::PSF1\n",
    "# P8R2_CLEAN_V6::PSF2\n",
    "# P8R2_CLEAN_V6::PSF3\n",
    "irf = 'P8R2_CLEAN_V6' \n",
    "\n",
    "\n",
    "# zmax [double]\n",
    "#          Maximum apparent zenith angle (degrees). It ranges from 0 to 180 (default).\n",
    "zmax = 90  # Max zenith angle cut.  90 is the standard cut for Pass8 data. \n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Some file paths containing fermi 3FGL catalog and the extended source templates\n",
    "\n",
    "# path to 3FGL file (or 2FGL)\n",
    "# can download this at http://fermi.gsfc.nasa.gov/ssc/data/access/lat/4yr_catalog/gll_psc_v14.fit\n",
    "#      (2FGL is at at: http://fermi.gsfc.nasa.gov/ssc/data/access/lat/2yr_catalog/gll_psc_v08.fit)\n",
    "# The extended source templates can be found here: http://fermi.gsfc.nasa.gov/ssc/data/access/lat/4yr_catalog/LAT_extended_sources_v15.tgz\n",
    "fglpath = '/data/gll_psc_v16.fit' # \n",
    "#fglpath = '/data/gll_psc_v08.fit' # 2FGL\n",
    "templateDir= '/data/Extended_archive_v15/Templates/'\n",
    "\n",
    "\n",
    "# Path to a fermi diffuse model.  Used only to calculate point source masking per Calore et al.\n",
    "# Can get this at http://fermi.gsfc.nasa.gov/ssc/data/access/lat/BackgroundModels.html\n",
    "path_to_diffuse_model = '/data/fermi_background_models/gll_iem_v06.fits'\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# Run this thing....\n",
    "A = Analysis.Analysis(tag, basepath, \n",
    "                      phfile_raw, scfile, fglpath, templateDir, \n",
    "                      2**healpix_order, \n",
    "                      E_min, E_max, gamma, n_bins, prefix_bins,\n",
    "                      evclass,  zmax, irf, evtype, gtfilter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not yet generated the Fermitools exposure files so we can ignore the warning for now. \n",
    "\n",
    "# Loading the Analysis\n",
    "\n",
    "The result above is a GammaLiek analysis file saved under \"\\$basepath/\\$tag.GLanalysis\".  This contains all of the analyis settings that will be needed in the future so we will be able to quickly load an analysis and get to work.  To load our analysis, we can use the following (replace the path of course):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: precomputed exposure map not found.  Reverting to slower methods, but you should run Analysis.GenExposureMap() for substantial speed increase.\n"
     ]
    }
   ],
   "source": [
    "basepath = '/data/GammaLike/testing/'\n",
    "tag = 'P8R2_CLEAN_V6_calore' \n",
    "A = Analysis.Load(basepath+tag+'.GLanalysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the required Fermi Science Tools output\n",
    "\n",
    "Now we need to generate the requisite exposure maps, PSF files, and photon data.  This is automated in GammaLike, but you must have the FermiScience tools in your system path. This is usually easily accomplished by adding the following lines to your ~/.bashrc file, (replace the paths!).\n",
    "\n",
    "export FERMI_DIR=\"/data/fermitools/ScienceTools-v10r0p5-fssc-20150518-x86_64-unknown-linux-gnu-libc2.19-0/x86_64-unknown-linux-gnu-libc2.19-0\"\n",
    "\n",
    "source $FERMI_DIR/fermi-init.sh\n",
    "\n",
    "\n",
    "\n",
    "This process will usually take a few hours because the Fermi Science Tools are very slow, and the datasets are big.  Luckily, it is a one time affair.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this script to generate the required fermitools files for this analysis.\n",
      "The script can be found at /data/GammaLike/testing/GenFermiData_P8R2_CLEAN_V6_calore_.sh\n",
      "WARNING: Possible mismatch between irf and evclass. Check Carefully.\n",
      "Get a beer. This will take a while...\n",
      "running gtselect\n",
      "Done.\n",
      "running gtmktime\n",
      "running gtltcube\n",
      "running gtbindef\n",
      "This is gtbindef version ScienceTools-v10r0p5-fssc-20150518\n",
      "running gtpsf\n",
      "Using evtype=3 (i.e., FRONT/BACK irfs)\n",
      "running gtbin\n",
      "This is gtbin version ScienceTools-v10r0p5-fssc-20150518\n",
      "running gtexpcube2\n",
      "Using evtype=3 (i.e., FRONT/BACK irfs)\n",
      "\n",
      "Working on file /data/fermi_data_6-26-15/lat_spacecraft_merged.fits\n",
      ".....................!\n",
      "Computing binned exposure map....................!\n",
      "\n",
      "Generating exposure map 100.00 %\n"
     ]
    }
   ],
   "source": [
    "# This will generate a shell script in the base directory specified above and execute it.  \n",
    "# This calls each of the FermiTools executables individually.  Ocassionally you may run into problems with\n",
    "# parameter values.  In this case, it can be helpful to exectute the scipt manually to debug.  \n",
    "\n",
    "A.GenFermiData(runscript=True)\n",
    "\n",
    "# Now we use the Fermi output to precompute some quantities for speed later.\n",
    "A.GenExposureMap()\n",
    "A.BinPhotons(outfile='binned_photons_'+A.tag+'.npy') # This is a healpix map of photon counts (for each energy+spatial bin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Point Source Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating ROI with point sources: 123 of 3034\n",
      "Populating ROI with point sources: 603 of 3034\n",
      "Populating ROI with point sources: 640 of 3034\n",
      "Populating ROI with point sources: 697 of 3034\n",
      "Populating ROI with point sources: 930 of 3034\n",
      "Populating ROI with point sources: 956 of 3034\n",
      "Populating ROI with point sources: 1001 of 3034\n",
      "Populating ROI with point sources: 1568 of 3034\n",
      "Populating ROI with point sources: 1624 of 3034\n",
      "Populating ROI with point sources: 1848 of 3034\n",
      "Populating ROI with point sources: 1963 of 3034\n",
      "Populating ROI with point sources: 1966 of 3034\n",
      "Populating ROI with point sources: 2020 of 3034\n",
      "Populating ROI with point sources: 2120 of 3034\n",
      "Populating ROI with point sources: 2275 of 3034\n",
      "Populating ROI with point sources: 2287 of 3034\n",
      "Populating ROI with point sources: 2355 of 3034\n",
      "Populating ROI with point sources: 2393 of 3034\n",
      "Populating ROI with point sources: 2406 of 3034\n",
      "Populating ROI with point sources: 2441 of 3034\n",
      "Populating ROI with point sources: 2500 of 3034\n",
      "Populating ROI with point sources: 2613 of 3034\n",
      "Populating ROI with point sources: 2639 of 3034\n",
      "Populating ROI with point sources: 2690 of 3034\n",
      "Populating ROI with point sources: 2700 of 3034\n",
      "Generating Point Source Map: 99.97 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------------------------\n",
    "# First we generate extended source templates.  PopulateROI will find all \n",
    "# point sources in the specified catalog and add their template to the \n",
    "# analysis template set.  For now we want them to be fixed so we will \n",
    "# merge them into a single template below.  This will make more sense \n",
    "# in later tutorials. \n",
    "A.PopulateROI([0,0], radius=360, fix_radius=360, include_point=False)\n",
    "\n",
    "# Merge all sources into one template. \n",
    "master = np.zeros(A.templateList['LMC'].healpixCube.shape)\n",
    "for key, t in A.templateList.items():\n",
    "    master += t.healpixCube.toarray()\n",
    "\n",
    "# Generate the point sources over the whole sky. This will also take a while...\n",
    "# Still some problems with point sources near the poles so just go to 85 degrees until fixed...\n",
    "A.GenPointSourceTemplate(pscmap=(A.basepath + '/PSC_' + A.tag + '_fgl3.npy'), l_range=(-180, 180), b_range=(-85, 85))\n",
    "\n",
    "# Add this point source template to the extended source template and resave it. \n",
    "master += np.load(A.basepath + '/PSC_' + A.tag + '_fgl3.npy')\n",
    "np.save(A.basepath + '/PSC_' + A.tag + '_fgl3_with_ext.npy', master)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have generated all of the files we need to start analyzing data. In the next tutorial we will set up an analysis over the full sky, and output a global diffuse model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
